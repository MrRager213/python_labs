from src.lib.text import normalize, count_freq, top_n, tokenize

print()

print('–ü—Ä–ò–≤–ï—Ç/n–ú–ò—Ä/t ‚Üí ', normalize('–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t'))
print("—ë–∂–∏–∫, –Å–ª–∫–∞ (yo2e=True) ‚Üí", normalize('—ë–∂–∏–∫, –Å–ª–∫–∞', yo2e=True))
print("Hello\r\nWorld  ‚Üí", normalize('Hello\r\nWorld'))
print("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ‚Üí ", normalize("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  "))

print()
print()

print("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä ‚Üí ", tokenize("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä ‚Üí "))
print("hello,world!!! ‚Üí ", tokenize("hello,world!!! ‚Üí "))
print("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ ‚Üí ", tokenize("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ ‚Üí "))
print("2025 –≥–æ–¥ ‚Üí ", tokenize("2025 –≥–æ–¥ ‚Üí "))
print("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ ‚Üí ", tokenize("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ ‚Üí "))

print()
print()

print('count_freq(["a","b","a","c","b","a"]) ‚Üí ', count_freq(["a","b","a","c","b","a"]))
print()
print('top_n(..., n=2) ‚Üí ', top_n(count_freq(["a","b","a","c","b","a"])))
print()
print('top_n(..., n=2) ["bb","aa","bb","aa","cc"]‚Üí ', top_n(count_freq(["bb","aa","bb","aa","cc"]), n=2))

print()
print()